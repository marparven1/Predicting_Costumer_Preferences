---
title: "Proyecto Blackwell Electronics. Data Science Process"
subtitle: "Módulo 3 Tarea 2: Predicción de la marca preferida por los clientes"
author: "Marta Venegas Pardo"
date: "8/Noviembre/2021"
output:
  prettydoc::html_pretty:
    theme: leonids
    highlight: github
    toc: yes
    toc_depth: 5
    number_sections: yes
  pdf_document:
    toc: yes
    toc_depth: 5
    number_sections: yes
lang: es
---

```{r setup, include=FALSE,message=FALSE,warning=FALSE}
knitr::opts_chunk$set(message=FALSE,warning=FALSE , echo = FALSE
  )
```

```{r librerías}
dire<-getwd() 
setwd(dire) 

# Librerías necesarias
library(dplyr)
library(kableExtra)
library(knitr)
# Gráficos
library(ggplot2)
## Matriz de correlación 
library(corrplot)
# Análisis exploratioro
library(SmartEDA)

# Modelado
#install.packages("caret", dependencies = c("Depends", "Suggests"))
library(C50)
library(caret)
library(mlbench)
```

# Introducción (definición del problema + objetivos)

## Objetivos

El equipo de ventas de Blackwell Electronics contrató una empresa de investigación de mercado para realizar una encuensta a los clientes con el siguiente **objetivo**:

-   Averiguar, de entre las marcas de ordenadores en venta, cual es la **marca preferida** por los clientes.

Con esta información, se podrán tomar decisiones sobre que fabricantes se debe buscar una relación estratégica mejor.

-   Sin embargo, como suele ocurrir al hacer una encuesta, las información sobre la preferencia de marcas de ordenador no quedó recogida por completo por lo que no tenemos resultados precisos.

-   Por ello debemos investigar si las respuestas a *otras preguntas* de la encuesta podrían ayudarnos a predecir la preferencia de marca de ordenador de nuestros clientes.

## Qué encontraremos en este informe

## Procedimiento para cumplir mis objetivos

-   Descripción de datos, pre-procesado, data cleaning y análisis exploratorio
-   Modelado a través de algoritmos de clasificacción (árboles de decisión), como por ejemplo C5.0 y RandomForest, entre otros (KNN, suppor vector machine, regresión logística (cuidado con la biclase))
-   Decisión del método que mejor funciona para predecir la marca de ordenador preferida por los clientes

# Descripción de los datos

-   Conjuntos de datos:

    -   **CompleteResponses**: Conjunto de datos con 10000 encuestas completas que usaremos para entrenar el modelo y construir un modelo predictivo
    -   **Survey Incomplete**: Dataset para testear el mejor modelo y tratar de predecir la marca preferida por los clientes
    -   **Survey key**: Encuesta (al final del documento)

```{r}
DatosCompletos<-read.csv(file="SurveyData/CompleteResponses.csv",header = TRUE,sep = ",",dec ="." )

DatosIncompletos<-read.csv(file="SurveyData/SurveyIncomplete.csv",header = TRUE,sep = ",",dec =".")
```

Vamos a visualizar unas cuantas líneas de los datos:

```{r}
DatosCompletos %>% 
  head(10) %>% 
  kable(booktabs=TRUE,caption = "Datos Completos") %>% 
  kable_styling(latex_options = "striped")
```

```{r}
DatosIncompletos %>% 
  head(10) %>% 
  kable(booktabs=TRUE,caption = "Datos incompletos") %>% 
  kable_styling(latex_options = "striped")
```

## Variables

-   Datos de entrenamiento y validación: 9898 registros, 7 variables
-   Datos de testeo: 5000 registros con las mismas 7 variables

En los conjuntos de datos encontramos 7 variables :

-   **Salario**: Salario anual del cliente, en dólares. (Variable numérica)

-   **Edad**: Edad, en años (Variable numérica)

-   **Elevel**: Nivel educativo más alto alcanzado. (Variable categórica). Corresponde a una escala de Likert

    -   0: Less than High School Degree
    -   1: High School Degree
    -   2: Some College
    -   3: 4-Year College Degree
    -   4: Master's, Doctoral or Professional Degree

-   **Car**: Marca de coche del cliente (1-20) (Variable categórica). Ver codificación al final del coumento (en la encuesta)

-   **Zip**: Código postal. (categórica)

    -   0: New England
    -   1: Mid-Atlantic
    -   2: East North Central
    -   3: West North Central
    -   4: South Atlantic
    -   5: East South Central
    -   6: West South Central
    -   7: Mountain
    -   8: Pacific

-   **Credit**: Crédito total disponible (variable numérica)

-   **Target. Brand**: Marca de ordenador preferida. (Variable categórica)

    -   0: Acer
    -   1: Sony

```{r}
# dim(DatosCompletos)
# dim(DatosInompletos)
```

# Preparación de los datos (Limpieza de datos)

En este paso del proceso, trataremos de encontrar, corregir o eliminar registros erróneos en nuestros datos. Para ello estudiaremos si todas las instancias están completas, si existen duplicados, valores atípicos,...

```{r}
str(DatosCompletos)
```

```{r}
str(DatosIncompletos)
```

```{r}
summary(DatosCompletos)
```

```{r}
summary(DatosIncompletos)
```

## Duplicados

Mostramos a continuación, las instancias duplicadas en nuestros datasets:

-   Duplicados en los datos de entrenamiento:

```{r}
DatosCompletos[duplicated(DatosCompletos)==TRUE,]
```

-   Duplicados en los datos de testeo:

```{r}
DatosCompletos[duplicated(DatosIncompletos)==TRUE,]
```

Por tanto, nn nuestros conjuntos de datos, no existen instancias duplicadas.

## Missing values

Ambos conjuntos de datos, estan completos.

```{r}
# summary(DatosCompletos)
# summary(DatosIncompletos)
# En caso de haber datos NA, lo veríamos aquí
```

## Outliers

-   En el dataset de entrenamiento *Datos Completos*, no encontramos valores atípicos.


```{r}
#boxplot(DatosCompletos)$out 
#boxplot(DatosIncompletos)$out
```

## Transformación de variables

### Factorización de las variables

Recodificamos las variables categóricas:

-   Target: Brand
-   Código Postal
-   Car
-   Nivel educativo

```{r}
DatosCompletosCategoricos = DatosCompletos
DatosCompletosCategoricos = DatosCompletosCategoricos%>% 
  mutate(
    Marca = factor(DatosCompletosCategoricos$brand, 
                   levels = c(0,1), 
                   labels = c("Acer", "Sony")),
    CodigoPostal = factor(DatosCompletosCategoricos$zipcode,
                          levels = c(0,1,2,3,4,5,6,7,8), 
                          labels =   c("New England","Mid-Atlantic","East North Central","West North Central","South Atlantic","East South Central","West South Central","Mountain","Pacific")),
    NivelEduc = factor(DatosCompletosCategoricos$elevel, 
                   levels = c(0,1,2,3,4), 
                   labels = c("Less HS", "HS", "SomeCollege","College Degree","Post College Decree")),
    MarcaCoche= factor(DatosCompletosCategoricos$car, 
                   levels = 1:20, 
                   labels=c("BMW","Buick","Cadillac","Chevrolet","Chrysler","Dodge","Ford","Honda","Hyundai","Jeep","Kia","Lincoln","Mazda","Mercedes Benz","Mitsubishi","Nissan","Ram","Subaru","Toyota","Other")
))%>% 
  select(c(1,2,10,11,9,6,8))


DatosCompletosCategoricos %>% head(10) %>% 
  kable(booktabs=TRUE, caption="Conjunto de datos completo")




DatosIncompletosCategoricos = DatosIncompletos
DatosIncompletosCategoricos = DatosIncompletosCategoricos%>% 
  mutate(
    Marca = factor(DatosIncompletosCategoricos$brand, 
                   levels = c(0,1), 
                   labels = c("Acer", "Sony")),
    CódigoPostal = factor(DatosIncompletosCategoricos$zipcode,
                          levels = c(0,1,2,3,4,5,6,7,8), 
                          labels =   c("New England","Mid-Atlantic","East North Central","West North Central","South Atlantic","East South Central","West South Central","Mountain","Pacific")),
    NivelEduc = factor(DatosIncompletosCategoricos$elevel, 
                   levels = c(0,1,2,3,4), 
                   labels = c("Less HS", "HS", "SomeCollege","College Degree","Post College Decree")),
    MarcaCoche= factor(DatosIncompletosCategoricos$car, 
                   levels = 1:20, 
                   labels=c("BMW","Buick","Cadillac","Chevrolet","Chrysler","Dodge","Ford","Honda","Hyundai","Jeep","Kia","Lincoln","Mazda","Mercedes Benz","Mitsubishi","Nissan","Ram","Subaru","Toyota","Other")
))%>% 
  select(c(1,2,10,11,9,6,8))



DatosIncompletosCategoricos %>%
  head(10) %>% 
  kable(booktabs=TRUE, caption="Conjunto de datos incompleto")

```

### Normalización de variables

## Creación de variables

De momento no es necesario.

# Análisis exploratorio

```{r}
# Nota para mí: Describiré el DSP, recordando las preguntas de Danielle Sherman
```

Comenzaremos con un breve resumen estadístico de nuestros datos:

```{r}
summary(DatosCompletosCategoricos)

summary(DatosIncompletosCategoricos)
```

-   **Salario**: Existe una grán diferencia entre el salario máximo (150000 dólares) y el salario mínimo (20000 dólares). El salario medio es similar en ambos conjuntos de datos:

    -   Datos de entrenamiento: 84871 dólares
    -   Datos de testeo: 85794 dólares

-   **Edad**: La edad media, en ambos conjuntos de datos es de 50 años. Nuestro comprador más joven tiene 20 años mientras que el más longevo tiene una edad de 80 años.

-   **Nivel educativo**: Las proporciones de compradores se mantienen en ambos conjuntos de datos:

    -   Less than HS: 20%
    -   High School: 19.6%
    -   Some college: 20%
    -   College Degree: 20\$\
    -   Post College Degree: 20%

```{r}
niv=c(2052,1948,1983,1947,1968)
nivComp=niv/sum(niv)*100
```

```{r}
niv2=c(989,988,1017,1000,1006)
nivComp2=niv2/sum(niv2)*100
```

-   **Marca Coche**: Las marcas de coches más frecuentes, en nuestros datos son:

    -   Datos de entrenamiento: Mitsubishi, Subaru, Honda, Buick, Ram y Chrysler
    -   Datos de testeo: Toyota, Subary, Nissan, Honda, Kia, Chrysler

-   **Código postal**: Las proporciones de compradores se mantienen en ambos conjuntos de datos:

    -   Mountain: 13%
    -   East South Central: 12.8%
    -   Pacific: 12.65%
    -   Mid-Atlantic: 12.5%
    -   West North Central: 12.4%
    -   (Other): 36.5%

```{r}
cuenta=c(1155,1135,1112,1108,1087,3216)
propcompleto=cuenta/sum(cuenta)*100
cuenta2= c( 569 ,565  , 560   , 549   , 549 ,1616)
propIncompleto=cuenta2/sum(cuenta2)*100
```

-   **Crédito**: De nuevo, en ambos conjuntos de datos, el crédito medio es prácticamente el mismo.

    -   Datos de entrenamiento: 249176 dólares
    -   Datos de testeo: 249546 dólares

## Resumen según preferencia de marca

```{r}
DatosCompletosCategoricos %>% 
  group_by(Marca) %>% 
  summarise(
  SalarioMedio = mean(salary)  ,
  EdadMedia = age %>% mean() ,
  CreditoMedio = credit %>% mean() ,
) %>% kable(booktabs=TRUE, caption="Resumen estadístico según marca preferida \n Variables Numéricas")
```


```{r}
DatosMarca = DatosCompletosCategoricos %>% 
  group_by(Marca) %>% 
  count()
```



```{r}
DatosMarca %>% 
  mutate(
    TOTAL = 3744+6154 ,
    Frecuencia =round( 100*(n / TOTAL) , 2 )) %>% 
  select(n,Frecuencia) %>% 
  kable(booktabs=TRUE, caption="Resumen estadístico según marca preferida",col.names = c("Marca","Número de clientes","Frecuencia"),align = "l")
```



En esta tabla observamos que existen más clientes que prefieren la marca Sony.


## Representaciones gráficas





```{r}
grafPrefe<-ggplot(DatosMarca,aes(x=Marca,y=n,color=Marca))+
  geom_col(fill="white")+
  labs(title="Marca preferida por los clientes",
       y="Número de clientes",x="Marca preferida",
       caption="Fuente: Elaboración propia")
grafPrefe
```

### Variables numéricas


#### Plot SmartEDA

```{r}
plot4 <- ExpNumViz(DatosCompletosCategoricos,target="Marca",type=1,nlim=3,fname=NULL,col=c("darkgreen","springgreen3","springgreen1"),Page=c(2,2),sample=3)
plot4[[1]]
```

#### Marca y edad

```{r}
p<-ggplot(DatosCompletosCategoricos, aes(x=Marca,y=age, color=Marca,group=Marca)) +
  geom_boxplot()+
  stat_summary(fun.y=mean, geom="point", shape=8, size=5, color="black", fill="red") +
  scale_y_continuous(breaks   = seq(0,85,by=5))+
  labs(title="BoxPlot" , subtitle= "Marca vs. Edad", caption="La estrella negra representa el salario medio \n Fuente: Elaboración propia. Conjunto de datos completos")
p
```

Observamos que para ambos grupos, la edad media de los clientes es prácticamente la misma, 50 años.

#### Marca y salario

```{r}
p<-ggplot(DatosCompletosCategoricos, aes(x=Marca,y=salary, color=Marca,group=Marca)) +
  geom_boxplot()+
  stat_summary(fun.y=mean, geom="point", shape=8, size=5, color="black", fill="red") +
  scale_y_continuous(breaks   = seq(40000,140000,by=10000))+
  labs(title="BoxPlot" , subtitle= "Marca vs. Salario", caption="La estrella negra representa el valor medio \n Fuente: Elaboración propia. Conjunto de datos completos")
p
```

Observamos que los clientes que prefieren la marca Sony tienen un salario medio más alto que aquellos cuya marca preferia es Acer:

-   Salario medio:

    -   Clientes que prefieren Acer: 74887.63 dólares
    -   Clientes que prefieren Sony: 90944.51 dólares

#### Marca y crédito

```{r}
p<-ggplot(DatosCompletosCategoricos, aes(x=Marca,y=credit, color=Marca,group=Marca)) +
  geom_boxplot()+
  stat_summary(fun.y=mean, geom="point", shape=4, size=5, color="black", fill="red") +
  scale_y_continuous(breaks   = seq(0,500000,by=50000))+
  labs(title="BoxPlot" , subtitle= "Marca vs. Crédito", caption="La estrella negra representa el valor medio \n Fuente: Elaboración propia. Conjunto de datos completos")
p
```

En ambos grupos el crédito medio es bastante similar.






### Variables categóricas

#### Marca de coche según marca preferida

```{r}
DatosSonyCoches =DatosCompletosCategoricos %>% 
  filter(Marca=="Sony") %>% 
  group_by(MarcaCoche) %>% 
  count()

DatosAcerCoches =DatosCompletosCategoricos %>% 
  filter(Marca=="Acer") %>% 
  group_by(MarcaCoche) %>% 
  count() 


par(mfrow=c(1,2))

ggplot(DatosSonyCoches,aes(x=reorder(MarcaCoche,n),y=n)) +
  geom_col(fill="lightgreen") +
    labs(title="Marca de coches",
         subtitle="Datos Sony",
       y="Frecuencia",x="Marcas de coche",
       caption="Fuente: Elaboración propia") +
  scale_y_continuous(labels = scales::comma) +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))




ggplot(DatosAcerCoches,aes(x=reorder(MarcaCoche,n),y=n)) +
  geom_col(fill="lightgreen") +
    labs(title="Marca de coches",
         subtitle="Datos Acer",
       y="Frecuencia",x="Marcas de coche",
       caption="Fuente: Elaboración propia") +
  scale_y_continuous(labels = scales::comma) +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))

```



-   Para ambos grupos, la marca Mitsubishi está en el top 3 de marcas que usan los clientes.

-   Marca preferida:

    -   Clientes Sony: Subaru
    -   Clientes Acer: Mitsubishi



```{r}
## DEBO UNIR EL GRÁFICO
#df.coc = data.frame(
#Edades = c(rep(seq(0,101),2)), cm = c(Coc_Mort$`2015`,
#Coc_Mort$`2016`),
#Año = c(rep("2016",nrow(tMortalidad2015)),
#rep("2017",nrow(tMortalidad2016))))
#
#ggplot(df.coc, aes(x = Edades, y= cm ,colour= Año)) + 
#  geom_line(alpha = 1,
#            linetype = "solid",
#            stat = "identity",
#            position = "identity", 
#            fill = "Black",
#            size = 0.4)+
#  labs(title="Cociente de mortalidad (Hombres/Mujeres). ", subtitle = "Galicia, 2015 y #2016.",
#y="Cociente de mortalidad",
#x="Edades",
#caption="Fuente: Elaboración propia") + scale_x_continuous(breaks = c(0,seq(5,100,by=5))) + #theme(axis.text.y = element_text(angle = 0, hjust = 1))+ theme_economist()
```


#### Nivel de educación según marca preferida

```{r}
# DatosSonyEducacion =DatosCompletosCategoricos %>% 
#   filter(Marca=="Sony") %>% 
#   group_by(NivelEduc) %>% 
#   count()
# 
# DatosAcerEducacion =DatosCompletosCategoricos %>% 
#   filter(Marca=="Acer") %>% 
#   group_by(NivelEduc) %>% 
#   count()
# 
# ggplot(DatosSonyEducacion,aes(x=reorder(NivelEduc,n),y=n)) +
#   geom_col(fill="lightgreen") +
#     labs(title="Nivel de educación",
#          subtitle="Datos Sony",
#        y="Número de clientes",x="Educación",
#        caption="Fuente: Elaboración propia") +
#   scale_y_continuous(breaks = seq(0,1600,by=100)) +
#   theme(axis.text.x = element_text(angle = 40, hjust = 1))
# 
# 
# 
# ggplot(DatosAcerEducacion,aes(x=reorder(NivelEduc,n),y=n)) +
#   geom_col(fill="lightgreen") +
#     labs(title="Nivel de educación",
#          subtitle="Datos Acer",
#        y="Número de clientes",x="Educación",
#        caption="Fuente: Elaboración propia") +
#   scale_y_continuous(breaks = seq(0,1600,by=100)) +
#   theme(axis.text.x = element_text(angle = 40, hjust = 1))
# 
# par(mfrow=c(1,1))
```

```{r}
plot5 <- ExpCatViz(DatosCompletosCategoricos,target="Marca",fname=NULL,clim=5,col=c("slateblue4","slateblue1"),margin=2,Page = c(2,1),sample=1)
plot5[[1]]
```



- Vemos que para ambas marcas preferidas, la mayoría de clientes prefiere la Marca Sony.
- La mayoría de clientes que prefieren Sony aún no ha terminado high School (63%)

#### Código postal según marca preferida

```{r}
DatosCP = DatosCompletosCategoricos %>% 
  group_by(Marca,CodigoPostal) %>% 
  count()
```

```{r}
# Interleaved histograms
ggplot(DatosCP, aes(x=CodigoPostal, y=n,color=Marca)) +
  geom_col(fill="white")+
  theme(axis.text.x = element_text(angle = 45, hjust = 1),legend.position="botton")+
  scale_y_continuous(breaks = seq(0,1200,by=100)) +
    labs(title="Código postal",
         subtitle="Según marca preferida",
       y="Número de clientes",x="Código Postal",
       caption="Fuente: Elaboración propia")


```

## Correlación

Como la variable objetivo es binaria, tenemos que estudiar la correlación de otra forma.

```{r}
M = cor(DatosCompletos)
corrplot(M, method = "circle",title = "Matriz de correlación")


# Visualice otros metodos gráficos como, 'circle', 'square', 'ellipse',
# 'number', 'shade', 'color', 'pie',
```

La variable más corrrealda con la variable objetivo, marca de ordenador preferida, es la variable salario (0.206)

```{r}
# Identificando variables predictoras muy correladas
highCorr <- sum(abs(M[upper.tri(M)]) > .999)
highCorr # No hay


findCorrelation(M, cutoff = .20)

highlyCorDescr <- findCorrelation(M, cutoff = .20)
filteredDescr <- DatosCompletos[,-highlyCorDescr]
descrCor2 <- cor(filteredDescr)
summary(descrCor2[upper.tri(descrCor2)])
```









```{r}
## Con SmartEDA
# ExpNumStat(DatosCompletosCategoricos,by="GA",gp="Marca",Qnt=seq(0,1,0.1),MesofShape=2,Outlier=TRUE,round=2)
```



```{r}
# ExpCTable(DatosCompletosCategoricos,Target="Marca",margin=1,clim=10,nlim=3,round=2,bin=NULL,per=F)
```
```{r}
# ExpCatStat(DatosCompletosCategoricos,Target="Marca",result = "IV",clim=10,nlim=5,bins=10,Pclass="Yes",plot=FALSE,top=20,Round=2)
```



```{r}
et4 <- ExpCatStat(DatosCompletosCategoricos,Target="Marca",result = "Stat",clim=10,nlim=5,bins=10,Pclass="Yes",plot=FALSE,top=20,Round=2)
# et4
```

```{r}
# varimp <- ExpCatStat(DatosCompletosCategoricos,Target="Marca",result = "Stat",clim=20,nlim=5,bins=6,Pclass="Yes",plot=TRUE,top=6,Round=2)

```








# Modelado y predicción de la marca preferida

```{r - semilla}
set.seed(17)
```


## Datos para la predicción de la marca preferida

Las variables que utilizaremos para predecir la marca preferida por los clientes son las siguientes:



```{r}
c("Salario","Edad","Nivel de educación","Marca de coche","Código Postal","Crédito") %>% 
  kable(booktabs=TRUE,col.names = "Variables predictoras") %>% 
  kable_styling(latex_options = "striped")
```



### División en datos de entrenamiento y testeo

Tomaremos una partición de 75% 25% para datos de entrenamiento y testeo

```{r - splitting ,echo=TRUE}
indicesEntrenamiento <- 
  createDataPartition(DatosCompletosCategoricos$Marca,
                      p = .75, list = FALSE)
DatosEntreamiento <- DatosCompletosCategoricos[indicesEntrenamiento,]
DatosTesteo <-DatosCompletosCategoricos[-indicesEntrenamiento,]
```


Debemos comprobar que las proporciones de clientes que prefieren cada marca se mantengan en ambos conjuntos de datos:

```{r}
round(prop.table(table(DatosEntreamiento$Marca)),3) %>% 
  kable(booktabs=TRUE, caption="Proporción para datos de Entrenamiento", col.names = c("Marca","Frecuencia")) 

```


```{r}
round(prop.table(table(DatosTesteo$Marca)),3) %>% 
  kable(booktabs=TRUE, caption="Proporción para datos de Testeo", col.names = c("Marca","Frecuencia")) 
```

Nos dan proporciones similares, en torno a un 38/62, por lo que procedemos a la construcción de los modelos

## Prueba de algoritmos, hiperparámetros y estrategias de optimización para predecir la marca preferida

Detección de los mejores algoritmos (decision tree classifiers methods):

#### Algoritmo 1: C5.0

Utilizaremos el algoritmo C5.0. Se trata de un algoritmo de **clasificación**, que genera árboles de decisión.
Aplicaremos el algoritmo a todas las columnas del dataset de entrenamiento, a excepción de la último columna 7, que es la que queremos predecir (Marca preferida)

###### Hiperparametros del algoritmo C5.0

- Trials: 7

###### Modelado

```{r}
#trials, model, winnow
modeloC5.0 <- C5.0(x = DatosEntreamiento[,-7] , 
                  y= DatosEntreamiento[,7] ,
                  
                  trials = 5   # 9 sube mucho el error
             #  ,  weights = c(38,62) # NO ESTOY SEGURA
                 ) 
#summary(modeloC5.0)
```

###### Resultados

```{r}
modeloC5.0$boostResults
```
Con estos hiperparámetros consigo un 7% de error.







```{r}
# Matriz de confusión
cat("Matriz de confusión \n")
(MC_C5.0<-matrix(c(2616,192,175,4441),byrow = TRUE,
                nrow = 2,ncol = 2,
                dimnames =  list(c("Acer","Sony"),c("Acer","Sony"))))
```



```{r}
# Importancia de las variables en el modelo

ImpC5.0<-cbind.data.frame(
  c("salary","age","MarcaCoche","credit","NivelEduc","CodigoPostal"),
  c( 100.00	, 84.19	, 16.49	, 15.93	,  8.78	,  2.64	))
colnames(ImpC5.0)=c("Variable","Importancia")

ImpC5.0 %>% 
  kable(booktabs=TRUE) %>% 
  kable_styling(latex_options = "striped")
```

Las variables más importantes son, con gran diferencia, salario y edad del cliente. Por el contrario, el Código postal parece no ser de gran importancia.


```{r}
ggplot(ImpC5.0, aes(x =sort( Variable)),) +
  stat_summary(aes(y = Importancia),  geom = "col",color="red",fill="#CC6666")+
  labs(title = "Histograma de la importancia de las variables en el modelo C5.0",caption = "Fuente: Elaboración propia \n En tanto por ciento")
```






#### Algoritmo 2: Random Forest

Algoritmo de clasificación

##### Hiperparametros

- Para validación cruzada, empleamos 10 grupos

```{r}
#10 fold cross validation
fitControl <- trainControl(method = "repeatedcv", number = 10, repeats = 1)
```

##### Modelado

```{r}
#train Random Forest Regression model with a tuneLenght = 1 (trains with 1 mtry value for RandomForest)
RandomForestR <- train(Marca~., 
                data = DatosEntreamiento, 
                method = "rf", 
                trControl=fitControl, 
                tuneLength = 1)

#training results
RandomForestR
```

```{r}
#rfFit1$results
#rfFit1$bestTune
```
- Precisión del 89.75%


```{r}
#rfFit1$metric
```



##### Resultados

#### Algoritmo 3: KNN

##### Hiperparametros...

##### Balanceo de datos...

#### Algoritmo 4: Gradient Boosting

##### Hiperparametros...

##### Balanceo de datos...




## Validación de los modelos para la predicción de la marca preferida

En este apartado comparamos mediante en Dataset de validación los modelos con todas las estrategias de optimización que hemos decidido aplicar en el apartado anterior.

### Algoritmo 1: C5.0

#### Hiperparametros alg 2...

#### Balanceo de datos si fuera necesario

### Algoritmo 2: Random Forest

#### Hiperparametros...

#### Balanceo de datos...

## Test del modelo final

### Evaluación del modelo final y testeo

### Análisis de error del modelo final





# Predicciones de la marca prefererida

# Conclusiones y recomendaciones

En este apartado exponemos aquellos aspectos interesantes para el negocio que son destacables y que permitan a la dirección establecer estrategias y tomar decisiones.

-   Métodos utilizados para modelar (resultados/métricas obtenidas)
-   Modelo elegido, porqué es el mejor, nivel de confianza de las predicciones
-   Las respuestas previstas a la pregunta de preferencia de marca para las instancias incompletas
-   Gráfico de las preferencias del clientes (comparación de predicción y valor real)

# Encuesta (Survey Questions and Response Key)

## ¿Cuál es su salario anual, sin incluir bonus? (Responder con un valor numérico)

## ¿Edad? (Responder con un valor numérico)

## ¿Cuál es el nivel más alto de educación que ha obtenido?

| Value | Description                               |
|-------|-------------------------------------------|
| 0     | Less than High School Degree              |
| 1     | High School Degree                        |
| 2     | Some College                              |
| 3     | 4-Year College Degree                     |
| 4     | Master's, Doctoral or Professional Degree |

## ¿Cuál es la marca de su coche?

Seleccione una entre las siguientes:

| Value | Description       |
|-------|-------------------|
| 1     | BMW               |
| 2     | Buick             |
| 3     | Cadillac          |
| 4     | Chevrolet         |
| 5     | Chrysler          |
| 6     | Dodge             |
| 7     | Ford              |
| 8     | Honda             |
| 9     | Hyundai           |
| 10    | Jeep              |
| 11    | Kia               |
| 12    | Lincoln           |
| 13    | Mazda             |
| 14    | Mercedes Benz     |
| 15    | Mitsubishi        |
| 16    | Nissan            |
| 17    | Ram               |
| 18    | Subaru            |
| 19    | Toyota            |
| 20    | None of the above |

## Código postal

| Value | Region             |
|-------|--------------------|
| 0     | New England        |
| 1     | Mid-Atlantic       |
| 2     | East North Central |
| 3     | West North Central |
| 4     | South Atlantic     |
| 5     | East South Central |
| 6     | West South Central |
| 7     | Mountain           |
| 8     | Pacific            |

## ¿Qué crédito tiene disponible? (Número)

## ¿Qué marca de ordenador prefiere?

| Value | Region |
|-------|--------|
| 0     | Acer   |
| 1     | Sony   |
