---
title: "Proyecto Blackwell Electronics. Data Science Process"
subtitle: "Módulo 3 Tarea 2: Predicción de la marca preferida por los clientes"
author: "Marta Venegas Pardo"
date: "8/Noviembre/2021"
output:
  prettydoc::html_pretty:
    theme: leonids
    highlight: github
    toc: yes
    toc_depth: 5
    number_sections: yes
lang: es
---

```{r setup, include=FALSE,message=FALSE,warning=FALSE}
knitr::opts_chunk$set(message=FALSE,warning=FALSE , echo = FALSE
  )
```

```{r librerías}
dire<-getwd() 
setwd(dire) 

# Librerías necesarias
library(dplyr)
library(kableExtra)
library(knitr)

# Gráficos
library(ggplot2)
library(scales)
## Matriz de correlación 
library(corrplot)
# Análisis exploratioro
library(SmartEDA)

# Modelado
#install.packages("caret", dependencies = c("Depends", "Suggests"))
library(C50)
library(caret)
library(mlbench)
library(gbm) # para VARIMP en GB
```

# Introducción (definición del problema + objetivos)

## Objetivos

El equipo de ventas de Blackwell Electronics contrató una empresa de investigación de mercado para realizar una encuensta a los clientes con el siguiente **objetivo**:

-   Averiguar, de entre las marcas de ordenadores en venta, cual es la **marca preferida** por los clientes.

Con esta información, se podrán tomar decisiones sobre que fabricantes se debe buscar una relación estratégica mejor.

-   Sin embargo, como suele ocurrir al hacer una encuesta, las información sobre la preferencia de marcas de ordenador no quedó recogida por completo por lo que no tenemos resultados precisos.

-   Por ello debemos investigar si las respuestas a *otras preguntas* de la encuesta podrían ayudarnos a predecir la preferencia de marca de ordenador de nuestros clientes.

## Qué encontraremos en este informe

- Descripción de los datos y variables predictoras de la marca preferida
- Limpieza de datos y preparación para el modelado
- Análisis exploratorio, resumen de mis datos, representaciones gráficas,
- Modelado, prueba de diferentes modelos con diferentes hiperparametrizaciones, entrenamiento de los modelos con validación y testeo de los modelos
- Test final del mejor modelo y predicción de la marca preferida en el conjunto de datos incompleto
- Conclusiones
- Encuesta




## Procedimiento para cumplir mis objetivos

-   Descripción de datos, pre-procesado, data cleaning y análisis exploratorio
-   Modelado a través de algoritmos de clasificacción (árboles de decisión), como por ejemplo C5.0 y RandomForest, entre otros (KNN y gradient boosting)
-   Decisión del método que mejor funciona para predecir la marca de ordenador preferida por los clientes
- Una vez tengamos el modelo final, predecir la marca preferida por los clientes en el dataset incompletos, ya que ha habido un error en la recogida de esta variable


# Descripción de los datos

-   Conjuntos de datos:

    -   **CompleteResponses**: Conjunto de datos con 10000 encuestas completas que usaremos para entrenar el modelo y construir un modelo predictivo
    -   **Survey Incomplete**: Dataset para testear el mejor modelo y tratar de predecir la marca de ordenador preferida por los clientes
    -   **Survey key**: Encuesta (al final del documento)

```{r}
DatosCompletos<-read.csv(file="SurveyData/CompleteResponses.csv",header = TRUE,sep = ",",dec ="." )

DatosIncompletos<-read.csv(file="SurveyData/SurveyIncomplete.csv",header = TRUE,sep = ",",dec =".")
```

Vamos a visualizar unas cuantas líneas de los datos:

```{r}
DatosCompletos %>% 
  head(10) %>% 
  kable(booktabs=TRUE,caption = "Datos Completos") %>% 
  kable_styling(latex_options = "striped")
```

```{r}
DatosIncompletos %>% 
  head(10) %>% 
  kable(booktabs=TRUE,caption = "Datos incompletos") %>% 
  kable_styling(latex_options = "striped")
```

## Variables

-   Datos de entrenamiento y validación: 9898 registros, 7 variables
-   Datos de testeo: 5000 registros con las mismas 7 variables

En los conjuntos de datos encontramos 7 variables :

-   **Salario**: Salario anual del cliente, en dólares. (Variable numérica)

-   **Edad**: Edad, en años (Variable numérica)

-   **Elevel**: Nivel educativo más alto alcanzado. (Variable categórica). Corresponde a una escala de Likert

    -   0: Less than High School Degree
    -   1: High School Degree
    -   2: Some College
    -   3: 4-Year College Degree
    -   4: Master's, Doctoral or Professional Degree

-   **Car**: Marca de coche del cliente (1-20) (Variable categórica). Ver codificación al final del coumento (en la encuesta)

-   **Zip**: Código postal. (categórica)

    -   0: New England
    -   1: Mid-Atlantic
    -   2: East North Central
    -   3: West North Central
    -   4: South Atlantic
    -   5: East South Central
    -   6: West South Central
    -   7: Mountain
    -   8: Pacific

-   **Credit**: Crédito total disponible (variable numérica)

-   **Target. Brand**: Marca de ordenador preferida. (Variable categórica)

    -   0: Acer
    -   1: Sony

```{r}
# dim(DatosCompletos)
# dim(DatosInompletos)
```


# Preparación de los datos (Limpieza de datos)

En este paso del proceso, trataremos de encontrar, corregir o eliminar registros erróneos en nuestros datos. Para ello estudiaremos si todas las instancias están completas, si existen duplicados, valores atípicos,...

```{r}
# str(DatosCompletos)
# str(DatosIncompletos)
# summary(DatosCompletos)
# summary(DatosIncompletos)
```



## Duplicados

Mostramos a continuación, las instancias duplicadas en nuestros datasets:

-   Duplicados en los datos de entrenamiento:

```{r}
DatosCompletos[duplicated(DatosCompletos)==TRUE,]
```

-   Duplicados en los datos de testeo:

```{r}
DatosCompletos[duplicated(DatosIncompletos)==TRUE,]
```

Por tanto, en nuestros conjuntos de datos, no existen instancias duplicadas.

## Missing values

Ambos conjuntos de datos, están completos, por lo que no tendremos que imputar datos o eliminar registro, que provocaría sesgo.

```{r}
# summary(DatosCompletos)
# summary(DatosIncompletos)
# En caso de haber datos NA, lo veríamos aquí
```

## Outliers

-   En el dataset de entrenamiento *Datos Completos*, no encontramos valores atípicos.


```{r}
boxplot(DatosCompletos,main="BoxPlot de las variables \n Datos Completos")$out 
#boxplot(DatosIncompletos)$out
```

## Transformación de variables

### Factorización de las variables

Recodificamos las variables categóricas:

-   Target: Brand
-   Código Postal
-   Car
-   Nivel educativo


```{r}
DatosCompletosCategoricos = DatosCompletos
DatosCompletosCategoricos = DatosCompletosCategoricos%>% 
  mutate(
    Marca = factor(DatosCompletosCategoricos$brand, 
                   levels = c(0,1), 
                   labels = c("Acer", "Sony")),
    CodigoPostal = factor(DatosCompletosCategoricos$zipcode,
                          levels = c(0,1,2,3,4,5,6,7,8), 
                          labels =   c("New England","Mid-Atlantic","East North Central","West North Central","South Atlantic","East South Central","West South Central","Mountain","Pacific")),
    NivelEduc = factor(DatosCompletosCategoricos$elevel, 
                   levels = c(0,1,2,3,4), 
                   labels = c("Less HS", "HS", "SomeCollege","College Degree","Post College Decree")),
    MarcaCoche= factor(DatosCompletosCategoricos$car, 
                   levels = 1:20, 
                   labels=c("BMW","Buick","Cadillac","Chevrolet","Chrysler","Dodge","Ford","Honda","Hyundai","Jeep","Kia","Lincoln","Mazda","Mercedes Benz","Mitsubishi","Nissan","Ram","Subaru","Toyota","Other")
))%>% 
  select(c(1,2,10,11,9,6,8))


DatosCompletosCategoricos %>% head(10) %>% 
  kable(booktabs=TRUE, caption="Conjunto de datos completo")




DatosIncompletosCategoricos = DatosIncompletos
DatosIncompletosCategoricos = DatosIncompletosCategoricos%>% 
  mutate(
    Marca = factor(DatosIncompletosCategoricos$brand, 
                   levels = c(0,1), 
                   labels = c("Acer", "Sony")),
    CodigoPostal = factor(DatosIncompletosCategoricos$zipcode,
                          levels = c(0,1,2,3,4,5,6,7,8), 
                          labels =   c("New England","Mid-Atlantic","East North Central","West North Central","South Atlantic","East South Central","West South Central","Mountain","Pacific")),
    NivelEduc = factor(DatosIncompletosCategoricos$elevel, 
                   levels = c(0,1,2,3,4), 
                   labels = c("Less HS", "HS", "SomeCollege","College Degree","Post College Decree")),
    MarcaCoche= factor(DatosIncompletosCategoricos$car, 
                   levels = 1:20, 
                   labels=c("BMW","Buick","Cadillac","Chevrolet","Chrysler","Dodge","Ford","Honda","Hyundai","Jeep","Kia","Lincoln","Mazda","Mercedes Benz","Mitsubishi","Nissan","Ram","Subaru","Toyota","Other")
))%>% 
  select(c(1,2,10,11,9,6,8))



DatosIncompletosCategoricos %>%
  head(10) %>% 
  kable(booktabs=TRUE, caption="Conjunto de datos incompleto")

```

### Normalización de variables

El salario y el crédito están ambas en la misma escala, y el resto de variables son categóricas, por lo que no es necesario escalar las variables.

## Creación de variables

No necesario






# Análisis exploratorio

```{r}
# Nota para mí: Describiré el DSP, recordando las preguntas de Danielle Sherman
```

Comenzaremos con un breve resumen estadístico de nuestros datos:

Dataset de datos Completos


```{r}
summary(DatosCompletosCategoricos)
```



Dataset de datos Incompletos

```{r}
summary(DatosIncompletosCategoricos)
```

-   **Salario**: Existe una grán diferencia entre el salario máximo (150000 dólares) y el salario mínimo (20000 dólares). El salario medio es similar en ambos conjuntos de datos:

    -   Datos de entrenamiento: 84871 dólares
    -   Datos de testeo: 85794 dólares

-   **Edad**: La edad media, en ambos conjuntos de datos es de 50 años. Nuestro comprador más joven tiene 20 años mientras que el más longevo tiene una edad de 80 años.

-   **Nivel educativo**: Las proporciones de compradores se mantienen en ambos conjuntos de datos:

    -   Less than HS: 20%
    -   High School: 19.6%
    -   Some college: 20%
    -   College Degree: 20\$\
    -   Post College Degree: 20%

```{r}
niv=c(2052,1948,1983,1947,1968)
nivComp=niv/sum(niv)*100
```

```{r}
niv2=c(989,988,1017,1000,1006)
nivComp2=niv2/sum(niv2)*100
```

-   **Marca Coche**: Las marcas de coches más frecuentes, en nuestros datos son:

    -   Datos de entrenamiento: Mitsubishi, Subaru, Honda, Buick, Ram y Chrysler
    -   Datos de testeo: Toyota, Subary, Nissan, Honda, Kia, Chrysler

-   **Código postal**: Las proporciones de compradores se mantienen en ambos conjuntos de datos:

    -   Mountain: 13%
    -   East South Central: 12.8%
    -   Pacific: 12.65%
    -   Mid-Atlantic: 12.5%
    -   West North Central: 12.4%
    -   (Other): 36.5%

```{r}
cuenta=c(1155,1135,1112,1108,1087,3216)
propcompleto=cuenta/sum(cuenta)*100
cuenta2= c( 569 ,565  , 560   , 549   , 549 ,1616)
propIncompleto=cuenta2/sum(cuenta2)*100
```

-   **Crédito**: De nuevo, en ambos conjuntos de datos, el crédito medio es prácticamente el mismo.

    -   Datos de entrenamiento: 249176 dólares
    -   Datos de testeo: 249546 dólares

## Resumen según preferencia de marca

```{r}
DatosCompletosCategoricos %>% 
  group_by(Marca) %>% 
  summarise(
  SalarioMedio = mean(salary)  ,
  EdadMedia = age %>% mean() ,
  CreditoMedio = credit %>% mean() ,
) %>% kable(booktabs=TRUE, caption="Resumen estadístico según marca preferida \n Variables Numéricas")
```


```{r}
DatosMarca = DatosCompletosCategoricos %>% 
  group_by(Marca) %>% 
  count()
```



```{r}
DatosMarca %>% 
  mutate(
    TOTAL = 3744+6154 ,
    Frecuencia =round( 100*(n / TOTAL) , 2 )) %>% 
  select(n,Frecuencia) %>% 
  kable(booktabs=TRUE, caption="Resumen estadístico según marca preferida",col.names = c("Marca","Número de clientes","Frecuencia"),align = "l")
```





En esta tabla observamos que existen más clientes que prefieren la marca Sony, en concreto, el 62.17% de nuestros clientes ha considerado que su marca preferida es Sony.


## Representaciones gráficas





```{r}
grafPrefe<-ggplot(DatosMarca,aes(x=Marca,y=n,color=Marca))+
  geom_col(fill="white")+
  labs(title="Marca preferida por los clientes",
       y="Número de clientes",x="Marca preferida",
       caption="Fuente: Elaboración propia")
grafPrefe
```


### Variables numéricas

Vamos a visualizar las diferentes variables en función de la marca preferida:


```{r}
#### Plot SmartEDA
plot4 <- ExpNumViz(DatosCompletosCategoricos,target="Marca",
                   type=1,
                   nlim=3,
                   fname=NULL,
                   col=c("darkgreen","springgreen3","springgreen1"),
                   Page=c(1,3),
                   sample=3,
                   gtitle = "BoxPlot")
plot4[[1]]
```

#### Marca y edad

```{r}
p<-ggplot(DatosCompletosCategoricos, aes(x=Marca,y=age, color=Marca,group=Marca)) +
  geom_boxplot()+
  stat_summary(fun.y=mean, geom="point", shape=8, size=5, color="black", fill="red") +
  scale_y_continuous(breaks   = seq(0,85,by=5))+
  labs(title="BoxPlot" , subtitle= "Marca vs. Edad", caption="La estrella negra representa el salario medio \n Fuente: Elaboración propia. Conjunto de datos completos")
p
```

Observamos que para ambos grupos, la edad media de los clientes es prácticamente la misma, 50 años.

#### Marca y salario

```{r}
p<-ggplot(DatosCompletosCategoricos, aes(x=Marca,y=salary, color=Marca,group=Marca)) +
  geom_boxplot()+
  stat_summary(fun.y=mean, geom="point", shape=8, size=5, color="black", fill="red") +
  scale_y_continuous(breaks   = seq(40000,140000,by=10000))+
  labs(title="BoxPlot" , subtitle= "Marca vs. Salario", caption="La estrella negra representa el valor medio \n Fuente: Elaboración propia. Conjunto de datos completos")
p
```

Observamos que los clientes que prefieren la marca Sony tienen un salario medio más alto que aquellos cuya marca preferia es Acer:

-   Salario medio:

    -   Clientes que prefieren Acer: 74887.63 dólares
    -   Clientes que prefieren Sony: 90944.51 dólares

#### Marca y crédito

```{r}
p<-ggplot(DatosCompletosCategoricos, aes(x=Marca,y=credit, color=Marca,group=Marca)) +
  geom_boxplot()+
  stat_summary(fun.y=mean, geom="point", shape=4, size=5, color="black", fill="red") +
  scale_y_continuous(breaks   = seq(0,500000,by=50000))+
  labs(title="BoxPlot" , subtitle= "Marca vs. Crédito", caption="La estrella negra representa el valor medio \n Fuente: Elaboración propia. Conjunto de datos completos")
p
```

En ambos grupos el crédito medio es bastante similar.






### Variables categóricas

#### Marca de coche según marca preferida

```{r}
DatosCompletosCategoricos %>%
  ggplot(aes(x = MarcaCoche , fill=Marca )) +
  geom_bar(position = "dodge") +
    labs(title="Marca de coche según marca preferida \n Sony vs Acer",
         subtitle="Gráfico de barras",
         y="Frecuencia",x="Marcas de coche",
         caption="Fuente: Elaboración propia") +
scale_y_continuous(labels = scales::comma) +
theme(axis.text.x = element_text(angle = 90, hjust = 1))
```


```{r}
# DatosSonyCoches =DatosCompletosCategoricos %>% 
#   filter(Marca=="Sony") %>% 
#   group_by(MarcaCoche) %>% 
#   count()
# 
# DatosAcerCoches =DatosCompletosCategoricos %>% 
#   filter(Marca=="Acer") %>% 
#   group_by(MarcaCoche) %>% 
#   count() 
# 
# 
# par(mfrow=c(1,2))
# 
# ggplot(DatosSonyCoches,aes(x=reorder(MarcaCoche,n),y=n)) +
#   geom_col(fill="FFDB6D") +
#     labs(title="Marca de coches",
#          subtitle="Datos Sony",
#        y="Frecuencia",x="Marcas de coche",
#        caption="Fuente: Elaboración propia") +
#   scale_y_continuous(labels = scales::comma) +
#   theme(axis.text.x = element_text(angle = 90, hjust = 1))
# 
# 
# 
# 
# ggplot(DatosAcerCoches,aes(x=reorder(MarcaCoche,n),y=n)) +
#   geom_col(fill="#00AFBB") +
#     labs(title="Marca de coches",
#          subtitle="Datos Acer",
#        y="Frecuencia",x="Marcas de coche",
#        caption="Fuente: Elaboración propia") +
#   scale_y_continuous(labels = scales::comma) +
#   theme(axis.text.x = element_text(angle = 90, hjust = 1))


```



-   Para ambos grupos, la marca Mitsubishi está en el top 3 de marcas que usan los clientes.

-   Marca preferida:

    -   Clientes Sony: Subaru
    -   Clientes Acer: Mitsubishi



```{r}
## DEBO UNIR EL GRÁFICO
#df.coc = data.frame(
#Edades = c(rep(seq(0,101),2)), cm = c(Coc_Mort$`2015`,
#Coc_Mort$`2016`),
#Año = c(rep("2016",nrow(tMortalidad2015)),
#rep("2017",nrow(tMortalidad2016))))
#
#ggplot(df.coc, aes(x = Edades, y= cm ,colour= Año)) + 
#  geom_line(alpha = 1,
#            linetype = "solid",
#            stat = "identity",
#            position = "identity", 
#            fill = "Black",
#            size = 0.4)+
#  labs(title="Cociente de mortalidad (Hombres/Mujeres). ", subtitle = "Galicia, 2015 y #2016.",
#y="Cociente de mortalidad",
#x="Edades",
#caption="Fuente: Elaboración propia") + scale_x_continuous(breaks = c(0,seq(5,100,by=5))) + #theme(axis.text.y = element_text(angle = 0, hjust = 1))+ theme_economist()
```


#### Nivel de educación según marca preferida

```{r}
# DatosSonyEducacion =DatosCompletosCategoricos %>% 
#   filter(Marca=="Sony") %>% 
#   group_by(NivelEduc) %>% 
#   count()
# 
# DatosAcerEducacion =DatosCompletosCategoricos %>% 
#   filter(Marca=="Acer") %>% 
#   group_by(NivelEduc) %>% 
#   count()
# 
# ggplot(DatosSonyEducacion,aes(x=reorder(NivelEduc,n),y=n)) +
#   geom_col(fill="lightgreen") +
#     labs(title="Nivel de educación",
#          subtitle="Datos Sony",
#        y="Número de clientes",x="Educación",
#        caption="Fuente: Elaboración propia") +
#   scale_y_continuous(breaks = seq(0,1600,by=100)) +
#   theme(axis.text.x = element_text(angle = 40, hjust = 1))
# 
# 
# 
# ggplot(DatosAcerEducacion,aes(x=reorder(NivelEduc,n),y=n)) +
#   geom_col(fill="lightgreen") +
#     labs(title="Nivel de educación",
#          subtitle="Datos Acer",
#        y="Número de clientes",x="Educación",
#        caption="Fuente: Elaboración propia") +
#   scale_y_continuous(breaks = seq(0,1600,by=100)) +
#   theme(axis.text.x = element_text(angle = 40, hjust = 1))
# 
# par(mfrow=c(1,1))
```





```{r}
DatosCompletosCategoricos %>%
  ggplot(aes(x = NivelEduc , fill=Marca )) +
  geom_bar(position = "dodge") +
    labs(title="Nivel de educación según marca preferida \n Sony vs Acer",
         subtitle="Gráfico de barras",
         y="Frecuencia",x="Marcas de coche",
         caption="Fuente: Elaboración propia") +
scale_y_continuous(labels = scales::comma) +
theme(axis.text.x = element_text(angle = 45, hjust = 1))

# Con otra librería
# plot5 <- ExpCatViz(DatosCompletosCategoricos,target="Marca",fname=NULL,clim=5,co# l=c("slateblue4","slateblue1"),margin=2,Page = c(2,1),sample=1)
# plot5[[1]]
```



- Vemos que para ambas marcas preferidas, la mayoría de clientes prefiere la Marca Sony.
- La mayoría de clientes que prefieren Sony aún no ha terminado high School (63%)

#### Código postal según marca preferida

```{r}
DatosCP = DatosCompletosCategoricos %>% 
  group_by(Marca,CodigoPostal) %>% 
  count()
```

```{r}
# Interleaved histograms
# ggplot(DatosCP, aes(y=n ,x=CodigoPostal,color=Marca, fill=Marca)) +
#     # geom_bar(position = "dodge")
#   geom_col(fill="white")+
#   theme(axis.text.x = element_text(angle = 45, hjust = # 1),legend.position="botton")+
#   scale_y_continuous(breaks = seq(0,1200,by=100)) +
#     labs(title="Código postal",
#          subtitle="Según marca preferida",
#        y="Número de clientes",x="Código Postal",
#        caption="Fuente: Elaboración propia")


DatosCompletosCategoricos %>%
  ggplot(aes(x = CodigoPostal , fill=Marca )) +
  geom_bar(position = "dodge") +
  # geom_col(fill="white")+
    labs(title="Código Postal según marca preferida \n Sony vs Acer",
         subtitle="Gráfico de barras",
         y="Frecuencia",x="Marcas de coche",
         caption="Fuente: Elaboración propia") +
scale_y_continuous(labels = scales::comma) +
theme(axis.text.x = element_text(angle = 45, hjust = 1))

```

## Grado de asociación de las variables



```{r}
M = cor(DatosCompletos)
corrplot(M, method = "circle",title = "Matriz de correlación")


# Visualice otros metodos gráficos como, 'circle', 'square', 'ellipse',
# 'number', 'shade', 'color', 'pie',
```




La variable más corrrealda con la variable objetivo, marca de ordenador preferida, es la variable salario (0.206)


Como la variable objetivo es binaria y categórica, tenemos que estudiar la correlación de otra forma.

```{r}
# Identificando variables predictoras muy correladas
highCorr <- sum(abs(M[upper.tri(M)]) > .999)
highCorr # No hay


findCorrelation(M, cutoff = .20)

highlyCorDescr <- findCorrelation(M, cutoff = .20)
filteredDescr <- DatosCompletos[,-highlyCorDescr]
descrCor2 <- cor(filteredDescr)
# summary(descrCor2[upper.tri(descrCor2)])
```









```{r}
## Con SmartEDA
# ExpNumStat(DatosCompletosCategoricos,by="GA",gp="Marca",Qnt=seq(0,1,0.1),MesofShape=2,Outlier=TRUE,round=2)
```



```{r}
# ExpCTable(DatosCompletosCategoricos,Target="Marca",margin=1,clim=10,nlim=3,round=2,bin=NULL,per=F)
```
```{r}
# ExpCatStat(DatosCompletosCategoricos,Target="Marca",result = "IV",clim=10,nlim=5,bins=10,Pclass="Yes",plot=FALSE,top=20,Round=2)
```

Asociación de las variables con la variable objetivo: Marca de ordenador preferida:

```{r}
et4 <- ExpCatStat(DatosCompletosCategoricos,Target="Marca",result = "Stat",clim=10,nlim=5,bins=10,Pclass="Yes",plot=FALSE,top=20,Round=2)
et4
```
La variable que más asociación guarda con la variable objetivo es el Salario. Para el resto de variables, la relación es muy poca.



```{r}
# varimp <- ExpCatStat(DatosCompletosCategoricos,Target="Marca",result = "Stat",clim=20,nlim=5,bins=6,Pclass="Yes",plot=TRUE,top=6,Round=2)
```














# Modelado y predicción de la marca preferida

```{r - semilla}
#set.seed(17)
```


## Datos para la predicción de la marca preferida

Las variables que utilizaremos para predecir la marca preferida por los clientes son las siguientes:



```{r}
c("Salario","Edad","Nivel de educación","Marca de coche","Código Postal","Crédito") %>% 
  kable(booktabs=TRUE,col.names = "Variables predictoras") %>% 
  kable_styling(latex_options = "striped")
```



### División en datos de entrenamiento y testeo

Tomaremos una partición de 80% 20% para datos de entrenamiento y testeo

```{r - splitting ,echo=TRUE}
set.seed(17)
indicesEntrenamiento <- 
  createDataPartition(DatosCompletosCategoricos$Marca,
                      p = .8, list = FALSE)
DatosEntreamiento <- DatosCompletosCategoricos[indicesEntrenamiento,]
DatosTesteo <-DatosCompletosCategoricos[-indicesEntrenamiento,]

set.seed(17)
indicesValidacion <- createDataPartition(DatosEntreamiento$Marca,
                      p = .8, list = FALSE)
DatosEntreamientoValidacion <- DatosCompletosCategoricos[indicesValidacion,]
DatosTesteoValidacion <-DatosCompletosCategoricos[-indicesValidacion,]
```


Debemos comprobar que las proporciones de clientes que prefieren cada marca se mantengan en ambos conjuntos de datos:

```{r}
round(prop.table(table(DatosEntreamiento$Marca)),3) %>% 
  kable(booktabs=TRUE, caption="Proporción para datos de Entrenamiento", col.names = c("Marca","Frecuencia")) 
```


```{r}
round(prop.table(table(DatosTesteo$Marca)),3) %>% 
  kable(booktabs=TRUE, caption="Proporción para datos de Testeo", col.names = c("Marca","Frecuencia")) 
```

Nos dan proporciones similares, en torno a un 38/62, por lo que procedemos a la construcción de los modelos


## Prueba de algoritmos, hiperparámetros y estrategias de optimización para predecir la marca preferida

Detección de los mejores algoritmos (decision tree classifiers methods):

En primer lugar, para la replicación de los resultados, usamos la función trainControl.


```{r echo=TRUE}
# Para todos los modelos
fitControl <- trainControl(method = "repeatedcv", number = 10, repeats = 1,
                          # verboseIter =TRUE 
)
```


Vamos con los modelos para clasificar a la marca de ordenador preferida:


### Algoritmo 1: C5.0

Utilizaremos el algoritmo C5.0. Se trata de un algoritmo de **clasificación**, que genera árboles de decisión.
Aplicaremos el algoritmo a todas las columnas del dataset de entrenamiento, a excepción de la último columna 7, que es la que queremos predecir (Marca preferida)


#### Hiperparametros del algoritmo C5.0

- Número de intentos (tune length): 5
- Validación cruzaza con 10 grupos y una repetición

#### Modelado

```{r echo=TRUE}
set.seed(17)
modeloC5.0 <- train(Marca~., 
                data = DatosEntreamientoValidacion, 
                method = "C5.0", 
                trControl=fitControl, 
                tuneLength = 5)
# summary(modeloC5.0)

```



Veamos la importancia de las variables en mi modelo:


```{r}
ImpC5.0<-varImp(modeloC5.0)
ImpC5.0


ggplot(ImpC5.0 ) +
geom_point( color="white", size=4, alpha=0.5)+
  scale_y_continuous(breaks = seq(0,100,by=10))+
xlab('Variable')+
ylab('Importancia')+
labs(title = "Importancia de las variables",subtitle = "Modelo KNN",caption = "Fuente: elaboración propia")+
theme_minimal()
```
#### Resultados


Con estos hiperparámetros consigo un 6.4% de error.

Hay varias variables bastante importantes de cara a predecir la marca preferida (edad, salario, si el cliente tiene un Toyota o si tiene un graduado universitario)








### Algoritmo 2: Random Forest

Algoritmo de clasificación

#### Hiperparametros

- Número de intentos (tune length): 3
- Validación cruzaza con 10 grupos y una repetición
- Diferentes tamaños de muestra para ver con cuál obtengo mejores métricas
- mtry: 2, 18 y 34


#### Modelado

```{r}

set.seed(17)
RandomForestR <- train(Marca~., 
                data = DatosEntreamientoValidacion, 
                method = "rf", 
                trControl=fitControl, 
                tuneLength = 3)

#training results
RandomForestR
```

```{r}
ImpRF <- varImp(RandomForestR)

ggplot(ImpRF ) +
geom_point( color="green", size=4, alpha=0.5)+
  scale_y_continuous(breaks = seq(0,100,by=10))+
xlab('Variable')+
ylab('Importancia')+
labs(title = "Importancia de las variables",subtitle = "Modelo Random Forest",caption = "Fuente: elaboración propia")+
theme_minimal()
```

Las variables más importantes a la hora de clasificar a un nuevo individuo son el salario, la edad y el crédito disponible, es última con menor porcentaje.



#### Resultados

```{r}
RandomForestR$results
RandomForestR$bestTune
```


- Precisión del 92.36%
- Kappa: 83.90%

Hiperparámetros del mejor modelo: mtry=18

### Algoritmo 3: KNN

#### Hiperparametros


- Número de intentos (tune length): 3
- Validación cruzaza con 10 grupos y una repetición
- Prueba con k = 5,7,9 para obtener un k que optimice las métricas

#### Modelado 

```{r}

set.seed(17)
KNNmodel <- train(Marca~., 
                 data = DatosEntreamientoValidacion, 
                 method = "knn",
                 trControl=fitControl,
                 tuneLength = 3)
KNNmodel 
```


```{r}
ImpKNN<-varImp(KNNmodel,k=35)
ImpKNN


ggplot(ImpKNN ) +
geom_point( color="white", size=4, alpha=0.5)+
  scale_y_continuous(breaks = seq(0,100,by=10))+
xlab('Variable')+
ylab('Importancia')+
labs(title = "Importancia de las variables",subtitle = "Modelo KNN",caption = "Fuente: elaboración propia")+
theme_minimal()
```

La variable más importante a la hora de clasificar la marca preferida de un cliente es el salario, con un 100%. Muy alejado al resto de variables.

La siguiente variable con más importancia es la edad (8.44%). Es decir, tenemos unas métricas un poco pobres, y quizás sea porque el modelo depende tanto del salario, que no es capaz de clasificar bien la marca preferida de los clientes.


#### Gráfica del remuestreo

```{r}
ggplot(KNNmodel)+
  scale_x_continuous(breaks=seq(0,55,by=5))+
  scale_y_continuous(n.breaks = 10)+
  labs(title = "Precisión del modelo en función del valor de k")
```


#### Resultado 

Las mejores métricas se obtienen con los siguientes hiperparámetros:

- k = 9


Métricas obtenidas:

- Precisión: 71.11%
- Kappa: 38.64%




### Algoritmo 4: Stochastic Gradient Boosting (Automathic Grid)

#### Hiperparametros

Los hiperparámetros admisibles son:

- Número de árboles (iteraciones)
- Complejidad del árbol (interaction.depth)
- Learning rate: shrinkage
- Número mínimo de muestras de conjuntos de entrenamiento en un nodo para comenzar a dividir (n.minobsinnode)

Nosotros crearemos una malla con los siguientes hiperparámetros, para ver cuáles son aquellos que nos dan un modelo óptimo

- Max Depth: 1,2,3,4,5
- Número de árboles: 50 100 150 200 250
- Learning rate: 0.1
- Número de muestras: 7



#### Modelado 

```{r message=FALSE}
# Malla para hiperparámetros
gbmGrid <-  expand.grid(interaction.depth = c(1,2,3,4,5,9), 
                        n.trees = seq(50,250,by=50), 
                        shrinkage = 0.1,
                        n.minobsinnode = 7)


set.seed(17)
garbage <- capture.output(
GradientBoostingR <- train(Marca~., 
                data = DatosEntreamientoValidacion, 
                method = "gbm", 
                trControl=fitControl, 
              # tuneLength = 5, 
                tuneGrid = gbmGrid)
)
GradientBoostingR
```


```{r}
ImpGB <-varImp(GradientBoostingR,numTrees=30)
ImpGB


ggplot(ImpGB ) +
geom_point( color="red", size=4, alpha=0.6)+
  scale_y_continuous(breaks = seq(0,100,by=10))+
xlab('Variable')+
ylab('Importancia')+
labs(title = "Importancia de las variables",subtitle = "Modelo Gradient Boosting",caption = "Fuente: elaboración propia")+
theme_light() 

# ggplot(ImpGB)
```
En este modelo, las variables más importantes, con grán diferencia son: el salario (100) y la edad (71.35%).

#### Gráfica del remuestreo

Para examinar la relación entre la estimación del rendimiento del modelo y los parámetros de ajuste.

examinar la relación entre las estimaciones de rendimiento y los parámetros de ajuste

```{r}
trellis.par.set(caretTheme())
plot(GradientBoostingR,main="Precisión del modelo según hiperparámetros  \n Gradient Boosting Automatic Grid)")

  
#ggplot(GradientBoostingR)+
#labs(title = "Precisión del modelo en función del valor de k")
```




#### Resultados

 
Las mejores métricas se obtienen con los siguientes hiperparámetros:

- Número de árboles: 250
- Max Depth: 4
- Learning rate: 0.1
- n.minobsinnode = 7


Métricas obtenidas:

- Precisión: 92.48%
- Kappa: 84.17%










## Validación


Ahora clasificaremos la marca de ordenador preferida por los individuos con estos modelos sobre los datos de testeo validación, para ver con cuales obtengo mejores métricas, obteniendo así un modelo óptimo para realizar predicicones sobre mis datos incompletos.

### Algoritmo 1: C5.0

Hiperparámetros del mejor modelo:

```{r}
modeloC5.0$bestTune
```



Modelamos con estos hiperparámetros

```{r}
C50_Grid <-  expand.grid(trials=30, model="rules",winnow=FALSE)

set.seed(17)
BestModelC50 <- train(Marca~., 
                data = DatosEntreamientoValidacion, 
                method = "C5.0", 
                trControl=fitControl,
                tuneGrid = C50_Grid)
```

#### Predicciones y evaluación del rendimiento en datos de validación

```{r}
PredValC50<-predict(BestModelC50, newdata = DatosTesteoValidacion)
#DatosTesteoValidacion[DatosTesteoValidacion$Marca==PredValC50,]

confuC50<- confusionMatrix(PredValC50, DatosTesteoValidacion$Marca)
#table(Real=DatosTesteoValidacion$Marca,Pred=PredValC50)
confuC50

cat("Precisión:",100*confuC50$overall[1],"\n")
cat("Kappa:",100*confuC50$overall[2],"\n")



# cat("\n Matriz de confusión para el modelo C50: \n")
# confuC50$table
```




### Algoritmo 2: Random Forest

```{r}
RandomForestR$bestTune
```



Modelamos con estos hiperparámetros




```{r}
RF_Grid <-  expand.grid(model="rules",winnow=FALSE,trials=10)

set.seed(17)
BestModelRandomForest <- train(Marca~., 
                data = DatosEntreamientoValidacion, 
                method = "C5.0", 
                trControl=fitControl,
                tuneGrid = RF_Grid)
```


#### Predicciones y evaluación del rendimiento


```{r}
PredValRF<-predict(BestModelRandomForest, newdata = DatosTesteoValidacion)
#DatosTesteoValidacion[DatosTesteoValidacion$Marca==PredValC50,]

confuRF<-confusionMatrix(PredValRF, DatosTesteoValidacion$Marca)
# table(Real=DatosTesteoValidacion$Marca,Pred=PredValRF)
confuRF

cat("Precisión:",100*confuRF$overall[1],"\n")
cat("Kappa:",100*confuRF$overall[2],"\n")

#cat("\n Matriz de confusión para el modelo Random Forest: \n")
#confuRF$table

```





### Algoritmo 3: KNN


```{r}
KNNmodel$bestTune
```






#### Predicciones y evaluación del rendimiento


```{r}
PredValKnn<-predict(KNNmodel,newdata =DatosTesteoValidacion )

confuKnn<- confusionMatrix(PredValKnn, DatosTesteoValidacion$Marca)
#table(Real=DatosTesteoValidacion$Marca,Pred=PredValKnn)
confuKnn


cat("Precisión:",100*confuKnn$overall[1],"\n")
cat("Kappa:",100*confuKnn$overall[2],"\n")

# cat("\n Matriz de confusión para el modelo KNN: \n")
# confuKnn$table
```






### Algoritmo 4: Gradient Boosting


```{r}
GradientBoostingR$bestTune
```


Modelado con estos hiperparámetros

```{r }
# Malla para hiperparámetros
gbmBestGrid <-  expand.grid(interaction.depth = 4, 
                        n.trees = 250, 
                        shrinkage = 0.1,
                        n.minobsinnode = 7)


set.seed(17)
garbage <- capture.output(

BestGradientBoostingR <- train(Marca~., 
                data = DatosEntreamientoValidacion, 
                method = "gbm", 
                trControl=fitControl, 
                tuneGrid = gbmBestGrid )
)
#BestGradientBoostingR
```





#### Predicciones y evaluación del rendimiento

```{r}
PredValGB<-predict(BestGradientBoostingR, newdata = DatosTesteoValidacion)

confuGB<-confusionMatrix(PredValGB, DatosTesteoValidacion$Marca)
# table(Real=DatosTesteoValidacion$Marca,Pred=PredValGB)
confuGB


cat("Precisión:",100*confuGB$overall[1],"\n")
cat("Kappa:",100*confuGB$overall[2],"\n")

# cat("\n Matriz de confusión para el modelo Gradient Boosting: \n")
# confuGB$table
```







### Comparación de las métricas según los diferentes modelos


#### Métricas

Las métricas obtenidas son las siguientes:

```{r}

data.frame(
  `Modelo`=c("C50","Random Forest","KNN","Gradient Boosting"),
  `Precisión`=c(92.27,91.77,70.54,92.38),
  `Kappa` = c(83.51, 82.39,36.75,83.77)
) %>% 
  kable(booktabs=TRUE) %>% 
  kable_styling(latex_options = "striped")
```


Por tanto, el modelo con el que obtenemos una mejor precisión a la hora de clasificar la marca de ordenador preferida por los clientes es: Gradient Boosting.


```{r}
ggplotConfusionMatrix <- function(m){
  mytitle <- paste("Accuracy",100*round( (m$overall[1]),3),
                   "Kappa",   100*round( (m$overall[2]),3))
  p <-
    ggplot(data = as.data.frame(m$table) ,
           aes(x = Reference, y = Prediction)) +
    geom_tile(aes(fill = log(Freq)), colour = "white") +
    scale_fill_gradient(low = "white", high = "steelblue") +
    geom_text(aes(x = Reference, y = Prediction, label = Freq)) +
    theme(legend.position = "none") +
    ggtitle("Matriz de confusión",subtitle = mytitle)
  return(p)
}
```



#### Matrices de confusión


Vamos a representar las cuatro matrices de confusión

```{r}
cat("\n Matriz de confusión para el modelo C50: \n")
ggplotConfusionMatrix(confuC50)
```


```{r}
cat("\n Matriz de confusión para el modelo Gradient Boosting: \n")
ggplotConfusionMatrix(confuGB)
```

Únicamente 110 clientes que prefieren Acer han sido clasificados como que su marca preferida es Sony y sólo 161 que en realidad prefieren Sony han sido clasificados como que su marca de ordenador preferida es Acer.

Las métricas de este modelo son muy buenas.



```{r}
cat("\n Matriz de confusión para el modelo KNN: \n")
ggplotConfusionMatrix(confuKnn)
```

Con gan diferencia, el modelo KNN es el que peor clasifica la marca preferida por los clientes, tenemos casi el mismo número de aciertos al a hora de clasificar la marca acer (790) que de fallos (529)



```{r}
cat("\n Matriz de confusión para el modelo Random Forest: \n")
ggplotConfusionMatrix(confuRF)
```





Conclusión: El mejor modelo para clasificar la marca preferida para nuestros clientes es un modelo Gradient Boosting. Es el que nos proporciona mejores métricas







## Test del modelo final Gradient Boosting

### Evaluación del modelo final y testeo


```{r}
PredTestGB<-predict(BestGradientBoostingR, newdata = DatosTesteo)
confuGBTest<-confusionMatrix(PredTestGB, DatosTesteo$Marca)
# table(Real=DatosTesteoValidacion$Marca,Pred=PredValGB)
confuGBTest


cat("Precisión:",100*confuGBTest$overall[1],"\n")
cat("Kappa:",100*confuGBTest$overall[2],"\n")

# cat("\n Matriz de confusión para el modelo Gradient Boosting: \n")
# confuGB$table
```

Conclusiones:

 - Accuracy : 0.9272 . Si llega un nuevo cliente, cabe esperar que el modelo acierte a la hora de clasificar su marca de ordenador preferida en un 92.72%   
 - Sensitivity : 0.9225 . De nuevo, ante la llegada de un nuevo cliente que prefiere la marca Acer ,cabe esperar que el modelo acierte a la hora de clasificar su marca de ordenador preferida en un 92.25%         
 - Specificity : 0.9301 .  Ante la llegada de un nuevo cliente que prefiere la marca Sony ,cabe esperar que el modelo acierte a la hora de clasificar su marca de ordenador preferida en un 93.01%  
 
El modelo clasifica ligeramente mejor a los clientes que prefieren Sony, pero clasifica bien a ambos. La métrica es muy buena.




```{r}
ImpFinalGB<-varImp(BestGradientBoostingR )
ImpFinalGB


ggplot(ImpFinalGB ) +
geom_point( color="white", size=4, alpha=0.5)+
  scale_y_continuous(breaks = seq(0,100,by=10))+
xlab('Variable')+
ylab('Importancia')+
labs(title = "Importancia de las variables",subtitle = "Modelo Gradient Boosting",caption = "Fuente: elaboración propia")+
theme_minimal()
```

Las variables mas importantes y por tanto, determinantes de cara a clasificar la preferencia de marca de ordenador de los clientes son: salario (100%), edad  (80.7) y crédito(3.08%)







### Análisis de error del modelo final


```{r}
confuGBTest
```


```{r}
cat("\n Matriz de confusión para el modelo Gradient Boosting: \n")
ggplotConfusionMatrix(confuGBTest)
```

Únicamente hemos clasificado mal a Acer en 58 casos y a Sony en 86, las métricas son muy buenas.


Precisión: 

```{r}
round(confuGBTest$overall[1]*100,3)
```

Si llega un cliente nuevo, cabe esperar que acierte al clasificar su marca preferida de ordenador en un 92.74% de las veces.



```{r echo=TRUE}
postResample(pred = PredTestGB, obs = DatosTesteo$Marca) # PREDS Y OBS REALES
```



```{r}
BienClasificados <- 
DatosTesteo[DatosTesteo$Marca==PredTestGB,]

MalClasificados <- 
DatosTesteo[DatosTesteo$Marca!=PredTestGB,]



comparo <- cbind.data.frame(DatosTesteo$Marca,PredTestGB)


plot(comparo, main="Valores Reales vs Predicción \n Datos Test")

# Plot con ggplot2 
# grafComparacion<-ggplot(comparo,aes(x=Marca,y=n,color=Marca))+
#   geom_col(fill="white")+
#   labs(title="Marca preferida por los clientes",
#        y="Número de clientes",x="Marca preferida",
#        caption="Fuente: Elaboración propia")
# grafPrefe

```

Gráfico donde podemos ver que las barras más pequeñas son los errores, me equicoco muy poco.
Me equivoco en menos de un 10% para ambas categorías.


¿Cómo son los inidviduos bien clasificados?¿Y los mal clasificados?


```{r}
BienClasificados %>% summary()
```


```{r}
MalClasificados %>% summary()
```



## Predicciones de la marca prefererida en el dataset incompletos

Predicciones con el mejor modelo para los datos incompletos.


```{r}
PrediccionesIncompletas <- 
  predict(BestGradientBoostingR, newdata =DatosIncompletosCategoricos )

PrediccionesIncompletas %>% head()

DatosIncompletosCategoricos$MarcaPreferidaPred=PrediccionesIncompletas 

```




```{r}
SonyPrediccion <- DatosIncompletosCategoricos[DatosIncompletosCategoricos$MarcaPreferidaPred=="Sony",]
SonyPrediccion %>% summary()

# nrow(SonyPrediccion)
```


```{r}
AcerPrediccion <- DatosIncompletosCategoricos[DatosIncompletosCategoricos$MarcaPreferidaPred=="Acer",]
AcerPrediccion %>% summary()
# nrow(AcerPrediccion)
```


RESULTADOS COMENTADOS AL FINAL. EN EL APARTADO DE CONCLUSIONES

# Conclusiones y recomendaciones

En este apartado exponemos aquellos aspectos interesantes para el negocio que son destacables y que permitan a la dirección establecer estrategias y tomar decisiones.

## Métodos utilizados para modelar (resultados/métricas obtenidas)

Modelos: 

- C50
- Random Forest
- KNN
- Gradient Boosting

Las métricas obtenidas son las siguientes:

```{r}

data.frame(
  `Modelo`=c("C50","Random Forest","KNN","Gradient Boosting"),
  `Precisión`=c(92.27,91.77,70.54,92.38),
  `Kappa` = c(83.51, 82.39,36.75,83.77)
) %>% 
  kable(booktabs=TRUE) %>% 
  kable_styling(latex_options = "striped")
```



Modelo elegido: 

Gradient Boosting. Lo hemos elegido porque nos daba la mejor precisión a la hora de clasificar a los clientes. Su matriz de confusión en los datos de testeo era la siguiente:

```{r}
cat("\n Matriz de confusión para el modelo Gradient Boosting: \n")
ggplotConfusionMatrix(confuGBTest)
```

Únicamente hemos clasificado mal a Acer en 58 casos y a Sony en 86, las métricas son muy buenas.

Las variables más importantes a la hora de predecir la marca preferida de los clientes son las siguientes:

```{r}
ImpFinalGB
```


Estudiaremos el salario y la edad, que son las más importantes.


Ahora bien, nos preguntamos, ¿cómo son las características de los clientes que han sido clasificados de forma correcta y los que no? ( respecto a las variables más importantes):


- *Salario*:Menor salario máximo para los mal clasificados. El salario medio de los bien clasificados es 87074 euros mientras que el de los mal clasificados es 75374.

- *Edad*: Edad media de los clientes bien clasificados es de casi 50 años, prácticamente igual que la de los clientes en los que hemos cometido error.

- *El crédito* medio de los clientes bien clasificados (252107 euros) es menor que el de los mal clasificados (257756 euros)


- Gráficos del salario

```{r}
ggplot(data = MalClasificados,
       mapping = aes(x = salary,
                     fill = Marca)) +
  geom_histogram(bins = 12,
                 position = 'identity',
                 alpha = 0.5) +
  scale_x_continuous(breaks = seq(20000,130000,by=10000))+
  theme(axis.text.x = element_text(angle = 45, hjust = 1))+
  labs(title = 'Salario según Marca Preferida',
       fill = 'Marca',
       x = 'Salario',
       y = 'n',
       subtitle = 'Clientes mal clasificados',
       caption = 'Fuente: Elaboración propia')
```


Son los clientes mal clasificados, vemos como hay  muchos clientes clasificados como Sony siendo Acer que tienen salarios entre 55000 y 100000 dólares. En el extremo superior, se han clasificado mal muchos clientes con salario de más de 125000 dólares, todos han sido clasificado como Acer cuando preferían Sony.


```{r}
ggplot(data = BienClasificados,
       mapping = aes(x = salary,
                     fill = Marca)) +
  geom_histogram(bins = 12,
                 position = 'identity',
                 alpha = 0.5) +
  scale_x_continuous(breaks = seq(20000,155000,by=10000))+
  theme(axis.text.x = element_text(angle = 45, hjust = 1))+
  labs(title = 'Salario según Marca Preferida',
       fill = 'Marca',
       x = 'Salario',
       y = 'n',
       subtitle = 'Clientes bien clasificados',
       caption = 'Fuente: Elaboración propia')
```



Vemos como las gráficas son bastante diferentes, aquí vemos que hay muchos más clientes que prefieren Sony que tienen un salarios más altos que los de Acer. Para salarios entre 55000 y 100000 dólares, la mayoría de clientes prefieren ordenadores de la marca Acer.



- Para la edad: 


```{r}
ggplot(data = MalClasificados,
       mapping = aes(x = age,
                     fill = Marca)) +
  geom_histogram(bins = 20,
                 position = 'identity',
                 alpha = 0.5) +
  scale_x_continuous(breaks = seq(18,81,by=2))+
  theme(axis.text.x = element_text(angle = 45, hjust = 1))+
  labs(title = 'Edad según Marca Preferida',
       fill = 'Marca',
       x = 'Salario',
       y = 'n',
       subtitle = 'Clientes mal clasificados',
       caption = 'Fuente: Elaboración propia')
```


En la franja de edad de 23 a 33 años, nos hemos equivocado al clasificar la marca de ordenador preferida, la mayoría de errores está en que hemos clasificado como Acer en vez de Sony.

Para una edad desde 55 en adelante, la mayorría de errores vienen de haber clasificado la marca preferida como Sony, en vez de Acer.


```{r}
ggplot(data = BienClasificados,
       mapping = aes(x = age,
                     fill = Marca)) +
  geom_histogram(bins = 12,
                 position = 'identity',
                 alpha = 0.5) +
  scale_x_continuous(breaks = seq(18,81,by=2))+
  theme(axis.text.x = element_text(angle = 45, hjust = 1))+
  labs(title = 'Edad según Marca Preferida',
       fill = 'Marca',
       x = 'Salario',
       y = 'n',
       subtitle = 'Clientes bien clasificados',
       caption = 'Fuente: Elaboración propia')
```


















## RESULTADOS DE LA CLASIFICACIÓN EN DATOS INCOMPLETOS



Hemos obtenido la siguiente clasificación:

- 3084 clientes cuya marca preferida ha sido clasificada como Sony
- 1916 clientes cuya marca preferida ha sido clasificada como Acer


```{r}
DatosMarcaINC = DatosIncompletosCategoricos %>% 
  group_by(MarcaPreferidaPred) %>% 
  count()


grafPrefe2<-ggplot(DatosMarcaINC,aes(x=MarcaPreferidaPred,
                                                  y=n,color=MarcaPreferidaPred))+
  geom_col(fill="white")+
  labs(title="Marca preferida por los clientes",
       y="Número de clientes",x="Marca preferida",
       caption="Fuente: Elaboración propia")
grafPrefe2
```



```{r}
ggplot(data =  DatosIncompletosCategoricos,
       mapping = aes(x = age,
                     fill = MarcaPreferidaPred)) +
  geom_histogram(bins = 20,
                 position = 'identity',
                 alpha = 0.5) +
  scale_x_continuous(breaks = seq(18,81,by=2))+
  theme(axis.text.x = element_text(angle = 45, hjust = 1))+
  labs(title = 'Clasificación según Edad ',
       fill = 'Marca',
       x = 'Edad',
       y = 'n',
       subtitle = 'Datos Incompletos',
       caption = 'Fuente: Elaboración propia')
```


```{r}
ggplot(data =  DatosIncompletosCategoricos,
       mapping = aes(x = salary,
                     fill = MarcaPreferidaPred)) +
  geom_histogram(bins = 20,
                 position = 'identity',
                 alpha = 0.5) +
  scale_x_continuous(breaks = seq(20000,155000,by=10000))+
  theme(axis.text.x = element_text(angle = 45, hjust = 1))+
  labs(title = 'Clasificación según Salario',
       fill = 'Marca',
       x = 'Salario',
       y = 'n',
       subtitle = 'Datos Incompletos',
       caption = 'Fuente: Elaboración propia')
```




# Encuesta (Survey Questions and Response Key)

## ¿Cuál es su salario anual, sin incluir bonus? (Responder con un valor numérico)

## ¿Edad? (Responder con un valor numérico)

## ¿Cuál es el nivel más alto de educación que ha obtenido?

| Value | Description                               |
|-------|-------------------------------------------|
| 0     | Less than High School Degree              |
| 1     | High School Degree                        |
| 2     | Some College                              |
| 3     | 4-Year College Degree                     |
| 4     | Master's, Doctoral or Professional Degree |

## ¿Cuál es la marca de su coche?

Seleccione una entre las siguientes:

| Value | Description       |
|-------|-------------------|
| 1     | BMW               |
| 2     | Buick             |
| 3     | Cadillac          |
| 4     | Chevrolet         |
| 5     | Chrysler          |
| 6     | Dodge             |
| 7     | Ford              |
| 8     | Honda             |
| 9     | Hyundai           |
| 10    | Jeep              |
| 11    | Kia               |
| 12    | Lincoln           |
| 13    | Mazda             |
| 14    | Mercedes Benz     |
| 15    | Mitsubishi        |
| 16    | Nissan            |
| 17    | Ram               |
| 18    | Subaru            |
| 19    | Toyota            |
| 20    | None of the above |

## Código postal

| Value | Region             |
|-------|--------------------|
| 0     | New England        |
| 1     | Mid-Atlantic       |
| 2     | East North Central |
| 3     | West North Central |
| 4     | South Atlantic     |
| 5     | East South Central |
| 6     | West South Central |
| 7     | Mountain           |
| 8     | Pacific            |

## ¿Qué crédito tiene disponible? (Número)

## ¿Qué marca de ordenador prefiere?

| Value | Region |
|-------|--------|
| 0     | Acer   |
| 1     | Sony   |











