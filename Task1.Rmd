---
title: "Modulo 3"
subtitle: "Tarea 1- Empezando con R \n Análisis de Regresión"
author: "Marta Venegas Pardo"
output:
  prettydoc::html_pretty:
    theme: leonids
    highlight: github
    toc: yes
    toc_depth: 3
    number_sections: yes
  pdf_document:
    includes: null
    toc: yes
    toc_depth: 3
    number_sections: yes
    keep_tex: yes
    highlight: pygments
lang: es
---

```{r setup, include=FALSE,message=FALSE,warning=FALSE}
knitr::opts_chunk$set(echo = FALSE,message=FALSE,warning=FALSE)
```



```{r include=FALSE}
library(readr) 
?readr

dire<-getwd() 
setwd(dire) 

library(dplyr)
library(kableExtra)
library(knitr)
```

# Lectura de datos

```{r}
Cars<- read.csv(file = 'R_Tutorial_Data_Sets/cars.csv',header   = TRUE,sep=",")
colnames(Cars)<-c("Marca","Velocidad","Distancia")
Cars %>% 
  head() %>% 
  kable(booktabs=TRUE) %>% 
  kable_styling(latex_options = "striped")
```


```{r}
attributes(Cars)#List your attributes within your data set.
```


```{r}
summary(Cars) #Prints the min, max, mean, median, and quartiles of each attribute.
```

No hay valores nulos, si no tendríamos la información aqui


```{r}
str(Cars) #Displays the structure of your data set.
```

Variables:

- Marca
- Velocidad
- Distancia


```{r}
names(Cars) #Names your attributes within your data set.
```


```{r}
Cars$name.of.car #Will print out the instances within that particular column in your data set.
```

## Representaciones gráficas


### Histograma

```{r}
library(ggplot2)
par(mfrow=c(1,2))
qplot(Cars$Velocidad,
      geom="histogram",
      binwidth = 5,  
      main = "Histograma de la Velocidad", 
      xlab = "Velocidad", 
      ylab = "Frecuencia",
      fill=I("blue"), 
      col=I("red"), 
      alpha=I(.2))+
    scale_x_continuous(breaks = seq(from=0,to=25,by=5),
                   labels = c(0,5,10,15,20,25))
qplot(Cars$Distancia,
      geom="histogram",
      binwidth = 10,  
      main = "Histograma de la Distancia", 
      xlab = "Distancia", 
      ylab = "Frecuencia",
      fill=I("blue"), 
      col=I("red"), 
      alpha=I(.2))+
    scale_x_continuous(breaks = seq(from=0,to=120,by=10))
par(mfrow=c(1,1))
seq()
```

```{r}
ggplot(data=Cars, aes(Distancia,fill=Marca)) + 
  geom_histogram() # dibujamos el histograma
```




### Nube de puntos Distancia vs Velocidad


```{r}
#plot(Cars$Velocidad,Cars$Distancia)

#ggplot(data=Cars, aes(Velocidad, Distancia)) +
#geom_point() + # los puntos
#stat_smooth(se=FALSE)

 qplot(Velocidad, Distancia, data = Cars, 
       xlab = "Distancia", ylab = "Velocidad", 
       alpha = I(0.7), col=I("red"),
       main = "Distancia vs Velocidad \n Datos Cars")
```



Parece que existe una tendencia creciente.

### Diagrama de Caja y bigote (Marca vs Velocidad)


```{r}
#plot(Cars$Marca,Cars$Velocidad,
#     main="BoxPlot \n Marca vs Velocidad",
#     ylab="Velocidad",
#     xlab="Marca")


ggplot(Cars, aes(x=Marca, y=Velocidad)) + 
  geom_boxplot(outlier.colour="red", outlier.shape=8,outlier.size=)+
  stat_summary(fun.y=mean, geom="point", shape=23, size=4)+
  #coord_flip()
  ggpubr::rotate_x_text(angle = 45)
```


## Normal Quantile Plot- is a way to see if your data is normally distributed.


```{r}
par(mfrow=c(2,1))

qqnorm(Cars$Velocidad,main="Gráficos de normalidad \n Velocidad")
qqline(Cars$Velocidad, datax = FALSE, distribution = qnorm,col="red")

qqnorm(Cars$Distancia,main="Distancia")
qqline(Cars$Distancia, datax = FALSE, distribution = qnorm,col="red")
par(mfrow=c(1,1))
```

Gráficamente podríamos afirmar que la variable velocidad se ajusta a una normal, ya que los puntos están en torno a la recta, sobre todo en el centro. Existen mayores oscilaciones en los extremos.

Para la variable distancia deberíamos realizar test para afirmarlo con seguridad, aunque parece que si.



# Preprocesado de datos

```{r}
# names(Cars)<-c("Marca","Velocidad","Distancia")
```


```{r}
summary(Cars) #Will count how many NA’s you have.
```
 
No existen valores NA.


La dimensión de nuestros datos es la siguiente: `r dim(Cars)`

```{r}
#Cars
```

# DataSets de Entrenamiento y Testeo

```{r}
set.seed(12345)
```

Dividimos el dataset en 70$\%$ para entrenamiento y 30$\%$ para testeo.




```{r}
#splitting
LongitudEntrenamiento<-round(nrow(Cars)*0.7) 
LongitudTesteo<-nrow(Cars)-LongitudEntrenamiento
cat(" Longitud de datos de entrenamiento:",LongitudEntrenamiento , "\n",
    "Longitud de datos de testeo:",LongitudTesteo )
```



```{r}
#creating datasets
training_indices<-sample(seq_len(nrow(Cars)),size =LongitudEntrenamiento)

trainSet<-Cars[training_indices,]

testSet<-Cars[-training_indices,] 
```

```{r}
trainSet %>% 
  head() %>% 
  kable(booktabs=TRUE) %>% 
  kable_styling(latex_options = "striped")
```


```{r}
testSet %>% 
  head() %>% 
  kable(booktabs=TRUE) %>% 
  kable_styling(latex_options = "striped")
```


# Modelo de regresión lineal

```{r}
modelo1<-lm(Distancia ~ Velocidad, trainSet) # y~x
summary(modelo1)
```

Conclusiones:

- Modelo: $\text{Distancia}=-30.58 + 4.7858 \cdot \text{Velocidad}$

- p-valor: $2,2 \cdot 10^{-16} < \alpha = 0.05$, la velocidad afecta a la distancia de forma muy significativa, el p-valor es muy pequeño y el valor del estadístico es muy grande.

- $R^2 = 0.9127$. Tenemos un buen ajuste, el modelo explica un `r 0.9127*100` $\%$ de la variabilidad total del modelo.


# Predicciones

```{r}
Predicciones1<- predict(modelo1,testSet,interval = 'prediction')
Predicciones1 %>% 
  kable(booktabs=TRUE,caption = "Predicciones de la distancia. Intervalos de Confianza") %>% 
  kable_styling(latex_options = "striped")
```

```{r}
comparo <- cbind.data.frame(testSet[,3],Predicciones1[,1], testSet[,3]-Predicciones1[,1] )
names(comparo)<- c("Valor Real","Predicción","Error")
comparo %>% 
  kable(booktabs=TRUE) %>% 
  kable_styling(latex_options = "striped")
```

```{r}
# index <- testSet[,0]
index <- c(4	,	5	,	6		,	7	,15	,	18	,21	,23	,	27	,34,35	,	39,	42	,	45	,	47)
par(mfrow=c(1,1))

plot(index,comparo[,1], main = "Predicciones VS Valor real")
par(new=T)
plot(index,comparo[,2],col="red")
legend(1, 95, legend=c("Line 1", "Line 2"),
       col=c("red", "blue"), lty=1:2, cex=0.8)
```


